{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asignacion 2\n",
    "\n",
    "Todos los asignaciones serán presentadas utilizando los cuadernos de [Jupyter Notebook](http://jupyter.org/), además de respectivas pruebas como ejemplo, así como el uso de mediciones de velocidad de ejecución utilizando el comando `timeit` y algunos gráficos si fuese necesario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preguntas\n",
    "\n",
    "1. Presenta un reporte del siguiente artículo [Data Science, Machine Learning, and Statistics: what is in a name?](http://www.win-vector.com/blog/2013/04/data-science-machine-learning-and-statistics-what-is-in-a-name/).\n",
    "\n",
    "2. Revisa el simpático proyecto kickstarter [The Emoji Translation Project :The world needs an emoji translation engine. Help us build it using the power of crowdsourcing. ](https://www.kickstarter.com/projects/fred/the-emoji-translation-project). \n",
    "\n",
    "3. Leer el artículo de Paul Graham [A Plan for Spam](http://www.paulgraham.com/spam.html) y responder las siguientes  preguntas de acuerdo a lo que dice el autor y lo que piensas tu:\n",
    "\n",
    "   - ¿Cuáles son los componentes clave de su sistema de filtrado estadístico? En otras palabras, ¿cómo funciona?.\n",
    "   - Presenta una lista de beneficios del enfoque estadístico.\n",
    "\n",
    "4. Presenta un reporte de tus ideas con ejemplos  del siguiente artículo [Choosing a Machine Learning Classifier](http://blog.echen.me/2011/04/27/choosing-a-machine-learning-classifier/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is in a name?\n",
    "\n",
    "Existen muchos artículos que se pueden encontrar en internet, los cuales están etiquetados como \"Data Science\" sin embargo es interesante y importante saber que hay detrás de este para de palabras, se enfatiza que cuando se menciona Data Science, se está refiriendo a la recopilación y gestión de datos, la aplicación de técnicas de modelado y la aplicación de estadísticas críticas, todo esto permitiendo el despliegue de modelos de datos valiosos en la producción.\n",
    "Un ejemplo de esto es cuando un científico, que forma parte de un grupo de investigación, está trabajando en la simulación de la interacción entre ciertas moléculas biológicas, donde se utiliza una gran cantidad de datos, los cuales son muy valiosos en este proceso. Entonces cuando un trabajo y sus resultados están profundamente relacionado o depende fuertemente de los datos, entonces podríamos estar hablando de \"Data Science\".\n",
    "Además se presenta un análisis de distintas ciencias de la información tales como estadística, Machine Learning, minería de datos, informática, Big Data, analítica predictiva y Data Science.\n",
    "\n",
    "La estadística es el campo que trata con los datos con mayor portabilidad, lo que se refiere que no depende de un modelo físico. Las estadísticas generalmente se usan para saber que puede salir mal en un experimento y puede deducirse que errores pueden salir a partir del uso de un conjunto de datos, ya que poseen suficiente cantidad de técnicas que pueden resolver casi cualquier problema. Se puede decir que la mejor fuente de un buen trabajo estadístico son los malos experimentos ya que de ahí se obtienen ciertos errores que nos ayudarán a resolver problemas posteriores, si todos los experimentos se realizarían correctamente, no sería muy necesario el uso de estadísticas.\n",
    "\n",
    "Otra característica importante es que es el único campo que enfatiza los riesgos de los datos pequeños, el poder razonar a partir de pequeños conjuntos de datos, ya que este tipo conjunto de datos son costosos de producir. En cambio con los datos grandes es un poco distinto el análisis ya que aveces se consideran valiosos porque son las más baratos de producir, su valor recae en el hecho que son un buen filtro para un conjunto de datos más pequeño, que como mencionamos anteriormente es costoso de producir, asi que si desea producir datos realmente valiosos directamente tendrá que trabajar con datos pequeños y consultar con un buen estadístico.\n",
    "\n",
    "Machine learning es el campo que toma las riendas en aquel lugar donde los estadísticos temen entrar, esta rama tiene un concepto de lo que es trabajar con pequeños conjuntos de datos, sin embargo su principal objetivo es el crear modelos predictivos que sea indistinguible de un modelo correcto, lo cual es distinto respecto al pensamiento estadístico, ya que en este caso la estadística se preocupa por la creación de un modelo que sea exacto y además que sea correcto. Uno de los principales conceptos que se debe tener en cuenta cuando se habla de machine learning es que este está fuertemente relacionado con la optimización, entonces si se desea hacer un buen trabajo de machine learning se debe rehacer una predicción como un problema de optimización utilizando las técnicas oportunas para cada caso.\n",
    "\n",
    "El término de data mining es aquel que ahora la mayoría de personas relacionan con data science, sin embargo muchas de esas personas confunden estos dos términos ya que en realidad tienen dos enfoques distintos. EL objetivo de Data mining es principalmente el encontrar relaciones entre un conjunto de datos, no necesariamente realizar prediciones, pueden haber muchas variables independientes y encontrar relaciones entre estas variables  mediante agrupamiento o detección de carácteristicas pero no hay variables dependientes.\n",
    "\n",
    "La informática y bioinformática son términos que son importantes y de hecho sirven de mucho al momento de definir Data Science, si tomamos el término bioinformática y lo separamos en estadística y biología, nos quedamos con lo que es una infraestructura de datos y algoritmos de matching, además tenemos bases de datos y la creación y gestión de estos. \n",
    "\n",
    "Cuando se habla de Big Data, el cual es un término muy comentado en la actualidad en diversos campos de estudio, se refiere más que nada a la infraestructura o la palataforma superior en la cual se realiza el modelado, podemos mencionar MapReduce, Hadoop, noSQL, etc.\n",
    "\n",
    "El área de analítica predictiva puede definirse como el conjunto de técnicas que provienen de otros campos tales como estadística, machine learning, minería de datos, etc; que son usadas sobre un conjunto de datos históricos actuales para realizar predicciones para el futuro. Es un término que suele estar relacionado con Data Science, pero que no es exactamente este, ya que en la analítica se trata más de visualización, informes y un resumen de un conjunto de datos determinado.\n",
    "\n",
    "Ahora sí se menciona el tan esperado término, \"Data Science\", este campo usa varias técnicas y teoría de otros campos, tales como la matemática, ingeniería de datos, estadística, reconocimiento de patrones, etc; para la gestión de todo el proceso cuando se desea contruir un modelo, por esto se refiere al análisis empresarial, recopilación de datos, la administración de estos, la construcción y despliegue de modelos en producción.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lista de ejercicios\n",
    "\n",
    "Las referencias a los ejercicios son :\n",
    "\n",
    "   * Asignaciones de Andrew Ng de Stanford University y cursos en Coursera.\n",
    "   * David Barber, [Bayesian Reasoning and Machine Learning](http://web4.cs.ucl.ac.uk/staff/D.Barber/pmwiki/pmwiki.php?n=Brml.Online), Cambridge University Press, 2017.\n",
    "   * Pattern Recognition and Machine Learning de Chris Bishop 2006.\n",
    "   * Machine Learning Refined, Watt, Borhani, Katsaggelos 2016.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 . Este conjunto de problemas implica la implementación de varias variantes del algoritmo Perceptron. Antes de poder construir estos modelos y medir su rendimiento, divide tus datos de entrenamiento (es decir, `entrenamiento_spam.txt`) en un conjunto de entrenamiento y validación, poniendo los últimos 1000 correos electrónicos en el conjunto de validación. Por lo tanto, tendrá un nuevo conjunto de entrenamiento con 4000 correos electrónicos y un conjunto de validación con 1000 correos electrónicos. \n",
    "\n",
    "Explica por qué medir el rendimiento de su clasificador final sería problemático si no hubiera creado este conjunto de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=open(\"entrenamiento_spam.txt\",\"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 . Transforme todos los datos en vectores de características. Construya una lista de vocabulario usando solamente el conjunto de entrenamiento de 4000 correos electrónicos encontrando todas las palabras que aparecen en el conjunto de entrenamiento.\n",
    "\n",
    "Ten en cuenta que suponemos que los datos de los conjuntos de validación y prueba no se ven completamente cuando entrenamos nuestro modelo y, por lo tanto, no utilizamos ninguna información contenida en ellos. \n",
    "\n",
    "Ignora todas las palabras que aparecen en menos de X = 30 correos electrónicos del conjunto de 4000 mensajes de correo electrónico, esto es tanto un medio de prevenir el ajuste excesivo y de mejorar la escalabilidad. Para cada correo electrónico, transformarlo en un vector de características $\\mathbf{x}$ donde la i-ésima entrada, $x_i$, es 1 si la i-ésima palabra del vocabulario aparece en el correo electrónico y 0 en caso contrario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 .Implementar las funciones **entrenamiento_perceptron(datos)** y **prueba_perceptron(w, datos)**.\n",
    "\n",
    "La función `entrenamiento_perceptron(datos)` entrena un clasificador perceptron usando los ejemplos proporcionados a la función, y devuelve `w`, `k`, `iter`, el vector de clasificación final, el número de actualizaciones (errores) realizados y el número de pasadas los datos, respectivamente. \n",
    "\n",
    "Se puede  suponer que los datos de entrada proporcionados a la función son linealmente separables (por lo que el criterio de parada debe ser que todos los puntos estén clasificados correctamente).\n",
    "\n",
    "Para el caso  `w·x = 0`, predecir la clase +1 (spam). Para este ejercicio, no es necesario agregar una función de sesgo al vector de características \n",
    "\n",
    "La función `prueba_perceptron(w, datos)` debe tomar como entrada el vector de peso `w`  (el vector de clasificación a utilizar) y un conjunto de ejemplos. La función debe devolver el error de prueba, es decir, la fracción de ejemplos que son mal clasificados por w."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 .Entrene el clasificador lineal usando su conjunto de entrenamiento. ¿Cuántos errores se cometen antes de que termine el algoritmo? Prueba tu implementación `prueba_perceptron` con  los parámetros aprendidos y los datos de entrenamiento, asegurándose de que el error de entrenamiento es cero. A continuación, clasifique los correos electrónicos en su conjunto de validación. ¿Qué es el error de validación?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 .Para entender mejor cómo funciona este clasificador de spam, podemos inspeccionar los parámetros para ver qué palabras cree que el clasificador es la más predictiva a spam. Usando la lista de vocabulario junto con los parámetros aprendidos en la pregunta anterior, muestra las 15 palabras con los pesos más positivos. ¿Cuáles son las  15 palabras que tienen los pesos más negativos?.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 . Implementar el algoritmo de perceptron promedio, que es el mismo que tu implementación actual, pero que, en lugar de devolver el vector de peso final, devuelve el promedio de todos los vectores de peso considerados durante el algoritmo (incluyendo ejemplos donde no se cometió ningún error). El promedio reduce la varianza entre los diferentes vectores, y es un poderoso medio para evitar que el algoritmo de aprendizaje sea sobrefijado (sirviendo como un tipo de regularización)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7 .Uno debe esperar que el error de prueba disminuye a medida que aumenta la cantidad de datos de entrenamiento. Usando sólo las primeras N filas de tus datos de entrenamiento, ejecute tanto el algoritmo del perceptron como el  algoritmo de perceptron promedio en este conjunto de entrenamiento  y evalúe el error de validación correspondiente (usando todos los datos de validación). Hacer esto para N = 100, 200, 400, 800, 2000, 4000 y crear un gráfico del error de validación de ambos algoritmos como una función de N."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8 . También para N = 100, 200, 400, 800, 2000, 4000, crea un diagrama del número de iteraciones para el perceptrón como una función de N, donde por iteración nos referimos a un paso completo a través de los datos de entrenamiento. A medida que aumenta la cantidad de datos de entrenamiento, el margen del conjunto de entrenamiento disminuye, lo que generalmente conduce a un aumento en el número de iteraciones que el perceptron toma para converger.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9 . Prueba varias configuraciones de los algoritmos usando todos los 4000 datos de entrenamiento y encuentra una buena configuración con un error pequeño en su conjunto de validación. En particular, trata de cambiar la elección del algoritmo perceptron y el número máximo de iteraciones. \n",
    "\n",
    "Reporta el error de validación para varias de las configuraciones, qué configuración funciona mejor?\n",
    "\n",
    "Combina el conjunto de entrenamiento y el conjunto de validación (es decir, utiliza `entrenamiento_spam.txt`) y aprenda usando la mejor de las configuraciones encontradas anteriormente.\n",
    "\n",
    "¿Cuál es el error en el conjunto de pruebas, es decir, en  `prueba_spam.txt`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tu respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
